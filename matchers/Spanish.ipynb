{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b71907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1abec839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the text \n",
    "alltext=''\n",
    "file_names=['/es/test_v3.txt','/es/dev_100_v3.txt','/es/dev_500_v3.txt']\n",
    "for j in file_names:\n",
    "    text=pd.read_csv(os.getcwd()[:-8]+'langs'+j,delimiter='\\t',header=None,quoting=3)\n",
    "    text.columns=['id', 'text']\n",
    "    for i in text.iterrows():\n",
    "        try:\n",
    "            if int(i[1][0]):\n",
    "                alltext=alltext+' '+i[1][1]\n",
    "        except:\n",
    "               pass\n",
    "alltext_lower=''\n",
    "for i in alltext:\n",
    "    if i.isupper():\n",
    "        alltext_lower=alltext_lower+i.lower()\n",
    "    else:\n",
    "        alltext_lower=alltext_lower+i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b6fd3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized=[]\n",
    "tokenized_strings=[]\n",
    "#Loading in the tokenized data\n",
    "with open(os.getcwd()[:-8]+'multilexnorm/data/es/train.norm') as text:\n",
    "    temp_list=[]\n",
    "    temp_string=''\n",
    "\n",
    "    for i in text:\n",
    "        if i.strip()!='':\n",
    "            temp_list.append(re.findall('.+\\t',i.strip())[0][:-1])\n",
    "            temp_string=temp_string+re.findall('.+\\t',i.strip())[0][:-1]+'omega_ts'\n",
    "        else:\n",
    "            tokenized.append(temp_list)\n",
    "            tokenized_strings.append(temp_string)\n",
    "            temp_list=[]\n",
    "            temp_string=''\n",
    "\n",
    "with open(os.getcwd()[:-8]+'multilexnorm/data/es/test.norm') as text:\n",
    "    temp_list=[]\n",
    "    temp_string=''\n",
    "\n",
    "    for i in text:\n",
    "        if i.strip()!='':\n",
    "            temp_list.append(re.findall('.+\\t',i.strip())[0][:-1])\n",
    "            temp_string=temp_string+re.findall('.+\\t',i.strip())[0][:-1]+'omega_ts'\n",
    "        else:\n",
    "            tokenized.append(temp_list)\n",
    "            tokenized_strings.append(temp_string)\n",
    "            temp_list=[]\n",
    "            temp_string=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a856bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edac8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "    \"\"\"\n",
    "    This makes all upper case letters lower\n",
    "    \"\"\"\n",
    "    new_text=''\n",
    "    for i in text:\n",
    "        if i.isupper():\n",
    "            new_text=new_text+i.lower()\n",
    "        else:\n",
    "            new_text=new_text+i\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc185905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_symbols(text):\n",
    "    \"\"\"\n",
    "    Function to get rid of annoying symbols in a token\n",
    "    \"\"\"\n",
    "    symbols=['.', '+', '*', '?', '^', '$', '(', ')', '[', ']', '{', '}', '|', '\\\\',';',':','',\"'\",'-','!']\n",
    "    new_token=''\n",
    "    for letter in text:\n",
    "        if letter in symbols:\n",
    "            new_token=new_token+'\\\\'+letter\n",
    "        else:\n",
    "            new_token=new_token+letter\n",
    "    return new_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c76ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_thing(j):\n",
    "    \"\"\"\n",
    "    This function will cut off the raw string based on the last token and the count of that token from a tokenized list\n",
    "    \"\"\"\n",
    "    symbols=['.', '+', '*', '?', '^', '$', '(', ')', '[', ']', '{', '}', '|', '\\\\',';',':','',\"'\",'-','!']\n",
    "    last_token=j[0][-1]\n",
    "    count_of_last=-1\n",
    "    og_sent=j[1]\n",
    "    new_sent=lower_case(j[1])\n",
    "    if set(last_token) & set(symbols):\n",
    "        last_token=kill_symbols(last_token)\n",
    "    for unique in j[0]:\n",
    "            if re.search(last_token,unique):\n",
    "                count_of_last+=len([x for x in re.finditer(last_token,unique)])\n",
    "\n",
    "    positions=[x for x in re.finditer(last_token,new_sent)]\n",
    "    \n",
    "    cut_off=og_sent[:positions[count_of_last].span()[1]+1][:-1]\n",
    "    return cut_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12eadebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phrase(t_phrase, phrase):\n",
    "    \"\"\"\n",
    "    This function returns a score for how many consecutive tokens were found\n",
    "    \"\"\"\n",
    "    symbols=['.', '+', '*', '?', '^', '$', '(', ')', '[', ']', '{', '}', '|', '\\\\',';',':','',\"'\",'-','!']\n",
    "    count=0\n",
    "    user_count=0\n",
    "    cont=0\n",
    "    cont_flag=1\n",
    "    same_flag=0\n",
    "    t_length=sum([len(x)+1 for x in t_phrase])\n",
    "    used_spans=[]\n",
    "    t0=kill_symbols(t_phrase[0])\n",
    "    t1=kill_symbols(t_phrase[1])\n",
    "\n",
    "    if re.search(t0,t1):\n",
    "        used_spans.append(re.search(t0, phrase).span()[0])\n",
    "        if re.search(t1,phrase):\n",
    "            if re.search(t1,phrase).span()[0] not in used_spans:\n",
    "                count+=1\n",
    "            \n",
    "    for token in t_phrase:\n",
    "        if set(token) & set(symbols):\n",
    "            token=kill_symbols(token)\n",
    "        if re.search(token, phrase):\n",
    "            if re.search(token, phrase).span()[0]>t_length:\n",
    "                cont_flag=0\n",
    "                cont=0\n",
    "            count=count+1+cont\n",
    "            cont+=1*cont_flag\n",
    "            \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a285e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols=['.', '+', '*', '?', '^', '$', '(', ')', '[', ']', '{', '}', '|', '\\\\',';',':','',\"'\",'-','!']\n",
    "counter=-1\n",
    "allcounts=[]\n",
    "matches=[]\n",
    "for t_phrase,t_string in zip(tokenized,tokenized_strings):\n",
    "    lengths=[]\n",
    "    counter+=1\n",
    "    tokens=len(t_phrase)\n",
    "    found=0\n",
    "    first_token=t_phrase[0]\n",
    "    if set(first_token) & set(symbols):\n",
    "        first_token=kill_symbols(first_token)\n",
    "    #get all places in the text where the first token is present and save the next 560 characters from there as a possible match\n",
    "    possible_matches=[x for x in re.finditer(first_token,alltext_lower)]\n",
    "    first_places=[x.span()[0] for x in possible_matches]\n",
    "    possible_phrases=[alltext[x:x+560] for x in first_places]\n",
    "    possible_phrases_lower=[alltext_lower[x:x+560] for x in first_places]\n",
    "    \n",
    "    #assign all possible matches scores\n",
    "    counts=[]\n",
    "    for phrase in possible_phrases_lower:\n",
    "        number=find_phrase(t_phrase, phrase)\n",
    "        counts.append(number)\n",
    "        if number>=max(counts):\n",
    "            try:\n",
    "                #this is just to make sure that in case of a weird edge case we know the length of the contenders\n",
    "                lengths.append([len(cut_thing([t_phrase,phrase])),phrase,number])\n",
    "            except:\n",
    "                pass\n",
    "    lengths=[x for x in lengths if x[2]==max(counts)]\n",
    "    if counts!=[]:\n",
    "        if counts.count(max(counts))!=1:#dealing with edge case where we need to prioritize shorter sentence\n",
    "            temp_len=[x[0] for x in lengths]\n",
    "            min_index=temp_len.index(min(temp_len))\n",
    "            matches.append([t_phrase,lengths[min_index][1],t_string])\n",
    "\n",
    "        else:         \n",
    "            max_index=counts.index(max(counts))\n",
    "            matches.append([t_phrase,possible_phrases[max_index],t_string])\n",
    "            allcounts.append(max(counts))\n",
    "\n",
    "    else:\n",
    "        matches.append([t_phrase,'nothing found',t_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71abc14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "#check that everything is found\n",
    "for i in matches:\n",
    "    if i[1]=='nothing found':\n",
    "        print(i)\n",
    "        counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9159dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_matches=[]\n",
    "#cut off based on the last token and save to disk\n",
    "for j in matches:\n",
    "    cut_matches.append([j[2],cut_thing(j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb94c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1=[]\n",
    "col2=[]\n",
    "for i in cut_matches:\n",
    "    col1.append(i[1])\n",
    "    col2.append(i[0])\n",
    "matched_df=pd.DataFrame([col1,col2])\n",
    "matched_df=matched_df.T\n",
    "matched_df.columns=['Original','Tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fee8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.to_csv(os.getcwd()[:-8]+'matched/matched_es.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a5f2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>PARA MI YA NO ERES NADA SOLO UNA SUCIA RAMERA.</td>\n",
       "      <td>paraomega_tsmiomega_tsyaomega_tsnoomega_tseres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>@adricastro6 nbeeeaaa y eso? Que le pasa a tu ...</td>\n",
       "      <td>@adricastro6omega_tsnbeeeaaaomega_tsyomega_tse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Con ganas de que venga a verme @JuananMarley m...</td>\n",
       "      <td>conomega_tsganasomega_tsdeomega_tsqueomega_tsv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Lo malo no es trompezar con la piedra si no qu...</td>\n",
       "      <td>loomega_tsmaloomega_tsnoomega_tsesomega_tstrom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Tengo ganas de que llegues ah casa yo mas....</td>\n",
       "      <td>tengoomega_tsganasomega_tsdeomega_tsqueomega_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Loo Exoo Maazooo dee Menooss Puuff :(</td>\n",
       "      <td>looomega_tsexooomega_tsmaazoooomega_tsdeeomega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>OYE OYE. K PASA AKI EH. :'( @Lauuuura99 @TriiHDD</td>\n",
       "      <td>oyeomega_tsoye.omega_tskomega_tspasaomega_tsak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Ya sabes que no resisto mucho una mirada, much...</td>\n",
       "      <td>yaomega_tssabesomega_tsqueomega_tsnoomega_tsre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>\" La sonrisa mas bella llega después de la lag...</td>\n",
       "      <td>\"omega_tslaomega_tssonrisaomega_tsmasomega_tsb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>@mariagodino94 @kimbherlynmo :O al vais a band...</td>\n",
       "      <td>@mariagodino94omega_ts@kimbherlynmoomega_ts:oo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Pues en mi pueblo no cae ni gota. Vivir en el ...</td>\n",
       "      <td>puesomega_tsenomega_tsmiomega_tspuebloomega_ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Empezando fuerte abril, con un desayuno como D...</td>\n",
       "      <td>empezandoomega_tsfuerteomega_tsabril,omega_tsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>A veces la solución está en desaparecer por un...</td>\n",
       "      <td>aomega_tsvecesomega_tslaomega_tssoluciónomega_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>@borjez_fdez96 no se me ha perdido nada en fra...</td>\n",
       "      <td>@borjez_fdez96omega_tsnoomega_tsseomega_tsmeom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>@Alwayslibelula @AnaDeLaFeBravo @xemaa_14 no q...</td>\n",
       "      <td>@alwayslibelulaomega_ts@anadelafebravoomega_ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Quiero tranquileo del bueno hoy..!!!</td>\n",
       "      <td>quieroomega_tstranquileoomega_tsdelomega_tsbue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>No sabes el daño que haces.</td>\n",
       "      <td>noomega_tssabesomega_tselomega_tsdañoomega_tsq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>antes no la queria y ahora quiero verla todos ...</td>\n",
       "      <td>antesomega_tsnoomega_tslaomega_tsqueriaomega_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Riesgo de lluvia hoy? Me cago en tus muertos</td>\n",
       "      <td>riesgoomega_tsdeomega_tslluviaomega_tshoy?omeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>@Anita_9930 macho tiras todo torpe</td>\n",
       "      <td>@anita_9930omega_tsmachoomega_tstirasomega_tst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>@CrisHMC ASDFGGBJKKKL ¿SI? JODER TENGO QUE EST...</td>\n",
       "      <td>@crishmcomega_tsasdfggbjkkklomega_ts¿si?omega_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>@MariaKodak ay no lo creo pero me has alegradp...</td>\n",
       "      <td>@mariakodakomega_tsayomega_tsnoomega_tsloomega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>@Ann_GV @Marisanchezt12 y yo a tii pelurroja:3</td>\n",
       "      <td>@ann_gvomega_ts@marisanchezt12omega_tsyomega_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Creo que despues de dar un paseito con simba m...</td>\n",
       "      <td>creoomega_tsqueomega_tsdespuesomega_tsdeomega_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Tu sabrás a lo que juegas,pero a mi no me la v...</td>\n",
       "      <td>tuomega_tssabrásomega_tsaomega_tsloomega_tsque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>@karinbourguigno pues sii aver si me dejan en ...</td>\n",
       "      <td>@karinbourguignoomega_tspuesomega_tssiiomega_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>@MTrin93 Lo de angustia sobra jajajajajaajaja</td>\n",
       "      <td>@mtrin93omega_tsloomega_tsdeomega_tsangustiaom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Buena caminata la de hoy cn @cato_alicun casi ...</td>\n",
       "      <td>buenaomega_tscaminataomega_tslaomega_tsdeomega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>En hora y media me voy para Coruña... ¡qué per...</td>\n",
       "      <td>enomega_tshoraomega_tsyomega_tsmediaomega_tsme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>En la vida con cuidado hay que caminar #andand...</td>\n",
       "      <td>enomega_tslaomega_tsvidaomega_tsconomega_tscui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>@elduke96 Pues por que ayer estuve en tu puebl...</td>\n",
       "      <td>@elduke96omega_tspuesomega_tsporomega_tsqueome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>@Ralfdez muchas gracias por seguirme :))) me a...</td>\n",
       "      <td>@ralfdezomega_tsmuchasomega_tsgraciasomega_tsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>@SoyElCapi muy cierto, a mi me ha pasado!!</td>\n",
       "      <td>@soyelcapiomega_tsmuyomega_tscierto,omega_tsao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>@nea_rufi @mariiaaro @ChuskaSf @NataaLia10 @Ca...</td>\n",
       "      <td>@nea_rufiomega_ts@mariiaaroomega_ts@chuskasfom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>no os esforcéis por encontrar a la mejor, por ...</td>\n",
       "      <td>noomega_tsosomega_tsesforcéisomega_tsporomega_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Como mola retwitear a las tontas de la zona. J...</td>\n",
       "      <td>comoomega_tsmolaomega_tsretwitearomega_tsaomeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Momentos de estos despues de una semana santa....</td>\n",
       "      <td>momentosomega_tsdeomega_tsestosomega_tsdespues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Típico: te ven en la calle y no te saludan, te...</td>\n",
       "      <td>típico:omega_tsteomega_tsvenomega_tsenomega_ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>La Gente Se Piensa Que Soy Estúpido ... Bueh S...</td>\n",
       "      <td>laomega_tsgenteomega_tsseomega_tspiensaomega_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>#dormiresdecobardes tony parker 23 ptos/ 5 rbt...</td>\n",
       "      <td>#dormiresdecobardesomega_tstonyomega_tsparkero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>@mariomarin35 Yo tambien que? jaja</td>\n",
       "      <td>@mariomarin35omega_tsyoomega_tstambienomega_ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Alomejor no nos a pillao todo el chaparron cor...</td>\n",
       "      <td>alomejoromega_tsnoomega_tsnosomega_tsaomega_ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>@MariaPerez89 @LuceroMexico @LuceroFanEspana  ...</td>\n",
       "      <td>@mariaperez89omega_ts@luceromexicoomega_ts@luc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>k #bien me a sentado esta ducha k me akabo d d...</td>\n",
       "      <td>komega_ts#bienomega_tsmeomega_tsaomega_tssenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Me quieren quitar el mobil al volver al instit...</td>\n",
       "      <td>meomega_tsquierenomega_tsquitaromega_tselomega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>En Londres sin parar y yo con estos pelos... L...</td>\n",
       "      <td>enomega_tslondresomega_tssinomega_tspararomega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>La vida nos da lo que nos merecemos si tratas ...</td>\n",
       "      <td>laomega_tsvidaomega_tsnosomega_tsdaomega_tsloo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Yo flipo demasiado, ai mai.</td>\n",
       "      <td>yoomega_tsflipoomega_tsdemasiado,omega_tsaiome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@criss_alcompas jajajajajaja entonces tu alli ...</td>\n",
       "      <td>@criss_alcompasomega_tsjajajajajajaomega_tsent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Mirian sabe lo q ha echo po eso llama a su mam...</td>\n",
       "      <td>mirianomega_tssabeomega_tsloomega_tsqomega_tsh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Original  \\\n",
       "150     PARA MI YA NO ERES NADA SOLO UNA SUCIA RAMERA.   \n",
       "151  @adricastro6 nbeeeaaa y eso? Que le pasa a tu ...   \n",
       "152  Con ganas de que venga a verme @JuananMarley m...   \n",
       "153  Lo malo no es trompezar con la piedra si no qu...   \n",
       "154      Tengo ganas de que llegues ah casa yo mas....   \n",
       "155              Loo Exoo Maazooo dee Menooss Puuff :(   \n",
       "156   OYE OYE. K PASA AKI EH. :'( @Lauuuura99 @TriiHDD   \n",
       "157  Ya sabes que no resisto mucho una mirada, much...   \n",
       "158  \" La sonrisa mas bella llega después de la lag...   \n",
       "159  @mariagodino94 @kimbherlynmo :O al vais a band...   \n",
       "160  Pues en mi pueblo no cae ni gota. Vivir en el ...   \n",
       "161  Empezando fuerte abril, con un desayuno como D...   \n",
       "162  A veces la solución está en desaparecer por un...   \n",
       "163  @borjez_fdez96 no se me ha perdido nada en fra...   \n",
       "164  @Alwayslibelula @AnaDeLaFeBravo @xemaa_14 no q...   \n",
       "165               Quiero tranquileo del bueno hoy..!!!   \n",
       "166                        No sabes el daño que haces.   \n",
       "167  antes no la queria y ahora quiero verla todos ...   \n",
       "168       Riesgo de lluvia hoy? Me cago en tus muertos   \n",
       "169                 @Anita_9930 macho tiras todo torpe   \n",
       "170  @CrisHMC ASDFGGBJKKKL ¿SI? JODER TENGO QUE EST...   \n",
       "171  @MariaKodak ay no lo creo pero me has alegradp...   \n",
       "172     @Ann_GV @Marisanchezt12 y yo a tii pelurroja:3   \n",
       "173  Creo que despues de dar un paseito con simba m...   \n",
       "174  Tu sabrás a lo que juegas,pero a mi no me la v...   \n",
       "175  @karinbourguigno pues sii aver si me dejan en ...   \n",
       "176      @MTrin93 Lo de angustia sobra jajajajajaajaja   \n",
       "177  Buena caminata la de hoy cn @cato_alicun casi ...   \n",
       "178  En hora y media me voy para Coruña... ¡qué per...   \n",
       "179  En la vida con cuidado hay que caminar #andand...   \n",
       "180  @elduke96 Pues por que ayer estuve en tu puebl...   \n",
       "181  @Ralfdez muchas gracias por seguirme :))) me a...   \n",
       "182         @SoyElCapi muy cierto, a mi me ha pasado!!   \n",
       "183  @nea_rufi @mariiaaro @ChuskaSf @NataaLia10 @Ca...   \n",
       "184  no os esforcéis por encontrar a la mejor, por ...   \n",
       "185  Como mola retwitear a las tontas de la zona. J...   \n",
       "186  Momentos de estos despues de una semana santa....   \n",
       "187  Típico: te ven en la calle y no te saludan, te...   \n",
       "188  La Gente Se Piensa Que Soy Estúpido ... Bueh S...   \n",
       "189  #dormiresdecobardes tony parker 23 ptos/ 5 rbt...   \n",
       "190                 @mariomarin35 Yo tambien que? jaja   \n",
       "191  Alomejor no nos a pillao todo el chaparron cor...   \n",
       "192  @MariaPerez89 @LuceroMexico @LuceroFanEspana  ...   \n",
       "193  k #bien me a sentado esta ducha k me akabo d d...   \n",
       "194  Me quieren quitar el mobil al volver al instit...   \n",
       "195  En Londres sin parar y yo con estos pelos... L...   \n",
       "196  La vida nos da lo que nos merecemos si tratas ...   \n",
       "197                        Yo flipo demasiado, ai mai.   \n",
       "198  @criss_alcompas jajajajajaja entonces tu alli ...   \n",
       "199  Mirian sabe lo q ha echo po eso llama a su mam...   \n",
       "\n",
       "                                             Tokenized  \n",
       "150  paraomega_tsmiomega_tsyaomega_tsnoomega_tseres...  \n",
       "151  @adricastro6omega_tsnbeeeaaaomega_tsyomega_tse...  \n",
       "152  conomega_tsganasomega_tsdeomega_tsqueomega_tsv...  \n",
       "153  loomega_tsmaloomega_tsnoomega_tsesomega_tstrom...  \n",
       "154  tengoomega_tsganasomega_tsdeomega_tsqueomega_t...  \n",
       "155  looomega_tsexooomega_tsmaazoooomega_tsdeeomega...  \n",
       "156  oyeomega_tsoye.omega_tskomega_tspasaomega_tsak...  \n",
       "157  yaomega_tssabesomega_tsqueomega_tsnoomega_tsre...  \n",
       "158  \"omega_tslaomega_tssonrisaomega_tsmasomega_tsb...  \n",
       "159  @mariagodino94omega_ts@kimbherlynmoomega_ts:oo...  \n",
       "160  puesomega_tsenomega_tsmiomega_tspuebloomega_ts...  \n",
       "161  empezandoomega_tsfuerteomega_tsabril,omega_tsc...  \n",
       "162  aomega_tsvecesomega_tslaomega_tssoluciónomega_...  \n",
       "163  @borjez_fdez96omega_tsnoomega_tsseomega_tsmeom...  \n",
       "164  @alwayslibelulaomega_ts@anadelafebravoomega_ts...  \n",
       "165  quieroomega_tstranquileoomega_tsdelomega_tsbue...  \n",
       "166  noomega_tssabesomega_tselomega_tsdañoomega_tsq...  \n",
       "167  antesomega_tsnoomega_tslaomega_tsqueriaomega_t...  \n",
       "168  riesgoomega_tsdeomega_tslluviaomega_tshoy?omeg...  \n",
       "169  @anita_9930omega_tsmachoomega_tstirasomega_tst...  \n",
       "170  @crishmcomega_tsasdfggbjkkklomega_ts¿si?omega_...  \n",
       "171  @mariakodakomega_tsayomega_tsnoomega_tsloomega...  \n",
       "172  @ann_gvomega_ts@marisanchezt12omega_tsyomega_t...  \n",
       "173  creoomega_tsqueomega_tsdespuesomega_tsdeomega_...  \n",
       "174  tuomega_tssabrásomega_tsaomega_tsloomega_tsque...  \n",
       "175  @karinbourguignoomega_tspuesomega_tssiiomega_t...  \n",
       "176  @mtrin93omega_tsloomega_tsdeomega_tsangustiaom...  \n",
       "177  buenaomega_tscaminataomega_tslaomega_tsdeomega...  \n",
       "178  enomega_tshoraomega_tsyomega_tsmediaomega_tsme...  \n",
       "179  enomega_tslaomega_tsvidaomega_tsconomega_tscui...  \n",
       "180  @elduke96omega_tspuesomega_tsporomega_tsqueome...  \n",
       "181  @ralfdezomega_tsmuchasomega_tsgraciasomega_tsp...  \n",
       "182  @soyelcapiomega_tsmuyomega_tscierto,omega_tsao...  \n",
       "183  @nea_rufiomega_ts@mariiaaroomega_ts@chuskasfom...  \n",
       "184  noomega_tsosomega_tsesforcéisomega_tsporomega_...  \n",
       "185  comoomega_tsmolaomega_tsretwitearomega_tsaomeg...  \n",
       "186  momentosomega_tsdeomega_tsestosomega_tsdespues...  \n",
       "187  típico:omega_tsteomega_tsvenomega_tsenomega_ts...  \n",
       "188  laomega_tsgenteomega_tsseomega_tspiensaomega_t...  \n",
       "189  #dormiresdecobardesomega_tstonyomega_tsparkero...  \n",
       "190  @mariomarin35omega_tsyoomega_tstambienomega_ts...  \n",
       "191  alomejoromega_tsnoomega_tsnosomega_tsaomega_ts...  \n",
       "192  @mariaperez89omega_ts@luceromexicoomega_ts@luc...  \n",
       "193  komega_ts#bienomega_tsmeomega_tsaomega_tssenta...  \n",
       "194  meomega_tsquierenomega_tsquitaromega_tselomega...  \n",
       "195  enomega_tslondresomega_tssinomega_tspararomega...  \n",
       "196  laomega_tsvidaomega_tsnosomega_tsdaomega_tsloo...  \n",
       "197  yoomega_tsflipoomega_tsdemasiado,omega_tsaiome...  \n",
       "198  @criss_alcompasomega_tsjajajajajajaomega_tsent...  \n",
       "199  mirianomega_tssabeomega_tsloomega_tsqomega_tsh...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "matched_df[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "537877c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13824\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in matched_df.iterrows():\n",
    "    for j in i[1]['Tokenized'].split('omega_ts')[:-1]:\n",
    "        count+=1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
